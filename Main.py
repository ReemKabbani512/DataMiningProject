# Ù…Ø´Ø±ÙˆØ¹ ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ù„Ø¹Ù†Ù‚Ø¯Ø©

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules
import sqlite3
import streamlit as st

# ===================================================
# 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ===================================================

# Ù‚Ø±Ø§Ø¡Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆØ§ØªÙŠØ±
df_invoices = pd.read_csv("Invoices_Dataset_for_Association_Rules.csv")
# Ù‚Ø±Ø§Ø¡Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
df_products = pd.read_csv("Extended_Products_Dataset__25_Products_ (1).csv")

# ===================================================
# 2. Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (EDA)
# ===================================================

print("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙˆØ§ØªÙŠØ±:")
print(df_invoices.info())
print(df_invoices.describe())

print("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª:")
print(df_products.info())
print(df_products.describe())

# ===================================================
# 3. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ===================================================

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
print("Missing values in products:\n", df_products.isnull().sum())

# ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø·
df_products.fillna(df_products.mean(numeric_only=True), inplace=True)

# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¥Ù† ÙˆØ¬Ø¯Øª
df_products.drop_duplicates(inplace=True)
df_invoices.drop_duplicates(inplace=True)

# ===================================================
# 4. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
# ===================================================

transactions = df_invoices.groupby('InvoiceID')['ProductID'].apply(list).tolist()
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_trans = pd.DataFrame(te_ary, columns=te.columns_)

# ===================================================
# 5. ØªØ·Ø¨ÙŠÙ‚ Apriori ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
# ===================================================

frequent_itemsets = apriori(df_trans, min_support=0.05, use_colnames=True)
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.6)
rules = rules.sort_values(by='lift', ascending=False)

# ===================================================
# 6. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹ÙÙ†Ù‚Ø¯Ø© (Ù…Ø¹ ÙˆØ¨Ø¯ÙˆÙ† Ø§Ù„Ø³Ø¹Ø±)
# ===================================================

features_with_price = ['Price', 'Rating', 'Stock', 'WarrantyYears', 'WeightKg', 'VolumeCm3', 'PowerWatt']
features_without_price = ['Rating', 'Stock', 'WarrantyYears', 'WeightKg', 'VolumeCm3', 'PowerWatt']

scaler = StandardScaler()

# Ù…Ø¹ Ø§Ù„Ø³Ø¹Ø±
X_with_price = scaler.fit_transform(df_products[features_with_price])
kmeans_with_price = KMeans(n_clusters=4, random_state=42)
df_products['Cluster_WithPrice'] = kmeans_with_price.fit_predict(X_with_price)

# Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø³Ø¹Ø±
X_without_price = scaler.fit_transform(df_products[features_without_price])
kmeans_without_price = KMeans(n_clusters=4, random_state=42)
df_products['Cluster_WithoutPrice'] = kmeans_without_price.fit_predict(X_without_price)

# ===================================================
# 7. ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª SQLite
# ===================================================

conn = sqlite3.connect('products_clusters.db')
cursor = conn.cursor()
#Ø§Ø°Ø§ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ø³Ø³Ù„ÙŠ ÙŠØ§Ù‡
cursor.execute("CREATE TABLE IF NOT EXISTS products ( \
    ProductID INTEGER PRIMARY KEY, \
    ProductName TEXT, \
    Category TEXT, \
    Brand TEXT, \
    SupplierCountry TEXT, \
    ConnectivityType TEXT, \
    MaterialType TEXT, \
    UsageType TEXT, \
    PriceCategory TEXT, \
    Price REAL, \
    Rating REAL, \
    Stock INTEGER, \
    WarrantyYears INTEGER, \
    WeightKg REAL, \
    VolumeCm3 REAL, \
    PowerWatt REAL, \
    Cluster_WithPrice INTEGER, \
    Cluster_WithoutPrice INTEGER \
)")
conn.commit()

for _, row in df_products.iterrows():
    cursor.execute(
        "INSERT OR REPLACE INTO products VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)",
        (
            row['ProductID'],
            row['ProductName'],
            row['Category'],
            row['Brand'],
            row['SupplierCountry'],
            row['ConnectivityType'],
            row['MaterialType'],
            row['UsageType'],
            row['PriceCategory'],
            row['Price'],
            row['Rating'],
            row['Stock'],
            row['WarrantyYears'],
            row['WeightKg'],
            row['VolumeCm3'],
            row['PowerWatt'],
            int(row['Cluster_WithPrice']),
            int(row['Cluster_WithoutPrice'])
        )
    )
conn.commit()
conn.close()

# ===================================================
# 8. ÙˆØ§Ø¬Ù‡Ø© Streamlit Ù„Ø¹Ø±Ø¶ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
# ===================================================

st.title("ğŸ” Ù†Ø¸Ø§Ù… ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø°ÙƒÙŠ")

conn = sqlite3.connect('products_clusters.db')
product_names = pd.read_sql_query("SELECT ProductName FROM products", conn)['ProductName'].tolist()
selected_product = st.selectbox("Ø§Ø®ØªØ± Ù…Ù†ØªØ¬Ù‹Ø§:", product_names)

product_data = pd.read_sql_query(f"SELECT * FROM products WHERE ProductName='{selected_product}'", conn)
cluster_label = product_data['Cluster_WithPrice'].values[0]

st.write(f" Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬ ÙŠÙ†ØªÙ…ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ù†Ù‚ÙˆØ¯ Ø±Ù‚Ù…: {cluster_label} (Ø¨Ø§Ø­ØªØ³Ø§Ø¨ Ø§Ù„Ø³Ø¹Ø±)")

recommended = pd.read_sql_query(f"""
SELECT ProductName FROM products 
WHERE Cluster_WithPrice={cluster_label} AND ProductName != '{selected_product}'
""", conn)

st.subheader("ğŸ“¦ Ù…Ù†ØªØ¬Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬:")
st.write(recommended)
conn.close()

